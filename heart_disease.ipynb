{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the pymice package \n",
    "# https://github.com/RianneSchouten/pymice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ma\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "\n",
    "def checks_input_mcar_tests(data):\n",
    "    \"\"\" Checks whether the input parameter of class McarTests is correct\n",
    "            Parameters\n",
    "            ----------\n",
    "            data:\n",
    "                The input of McarTests specified as 'data'\n",
    "            Returns\n",
    "            -------\n",
    "            bool\n",
    "                True if input is correct\n",
    "            \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print(\"Error: Data should be a Pandas DataFrame\")\n",
    "        return False\n",
    "\n",
    "    if not any(data.dtypes.values == np.float):\n",
    "        if not any(data.dtypes.values == np.int):\n",
    "            print(\"Error: Dataset cannot contain other value types than floats and/or integers\")\n",
    "            return False\n",
    "\n",
    "    if not data.isnull().values.any():\n",
    "        print(\"Error: No NaN's in given data\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def mcar_test(data):\n",
    "    \"\"\" Implementation of Little's MCAR test\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas DataFrame\n",
    "        An incomplete dataset with samples as index and variables as columns\n",
    "    Returns\n",
    "    -------\n",
    "    p_value: Float\n",
    "        This value is the outcome of a chi-square statistical test, testing whether the null hypothesis\n",
    "        'the missingness mechanism of the incomplete dataset is MCAR' can be rejected.\n",
    "    \"\"\"\n",
    "\n",
    "    if not checks_input_mcar_tests(data):\n",
    "        raise Exception(\"Input not correct\")\n",
    "\n",
    "    dataset = data.copy()\n",
    "    vars = dataset.dtypes.index.values\n",
    "    n_var = dataset.shape[1]\n",
    "\n",
    "    # mean and covariance estimates\n",
    "    # ideally, this is done with a maximum likelihood estimator\n",
    "    gmean = dataset.mean()\n",
    "    gcov = dataset.cov()\n",
    "\n",
    "    # set up missing data patterns\n",
    "    r = 1 * dataset.isnull()\n",
    "    mdp = np.dot(r, list(map(lambda x: ma.pow(2, x), range(n_var))))\n",
    "    sorted_mdp = sorted(np.unique(mdp))\n",
    "    n_pat = len(sorted_mdp)\n",
    "    correct_mdp = list(map(lambda x: sorted_mdp.index(x), mdp))\n",
    "    dataset['mdp'] = pd.Series(correct_mdp, index=dataset.index)\n",
    "\n",
    "    # calculate statistic and df\n",
    "    pj = 0\n",
    "    d2 = 0\n",
    "    for i in range(n_pat):\n",
    "        dataset_temp = dataset.loc[dataset['mdp'] == i, vars]\n",
    "        select_vars = ~dataset_temp.isnull().any()\n",
    "        pj += np.sum(select_vars)\n",
    "        select_vars = vars[select_vars]\n",
    "        means = dataset_temp[select_vars].mean() - gmean[select_vars]\n",
    "        select_cov = gcov.loc[select_vars, select_vars]\n",
    "        mj = len(dataset_temp)\n",
    "        parta = np.dot(means.T, np.linalg.solve(select_cov, np.identity(select_cov.shape[1])))\n",
    "        d2 += mj * (np.dot(parta, means))\n",
    "\n",
    "    df = pj - n_var\n",
    "\n",
    "    # perform test and save output\n",
    "    p_value = 1 - st.chi2.cdf(d2, df)\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work with a classification dataset on heart disease. \n",
    "\n",
    "Please check the description (heart-disease.names) and the data (cleveland.data) in the data folder.\n",
    "\n",
    "The code below is provided to load the data into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "\n",
      "   slope   ca  thal  num  \n",
      "0    3.0  0.0   6.0  0.0  \n",
      "1    2.0  3.0   3.0  2.0  \n",
      "2    2.0  2.0   7.0  1.0  \n",
      "3    3.0  0.0   3.0  0.0  \n",
      "4    1.0  0.0   3.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "# Let's load the data\n",
    "\n",
    "feature_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach',\\\n",
    "                'exang','oldpeak','slope','ca','thal']\n",
    "label = 'num'\n",
    "df = pd.read_csv('data/cleveland.data',header=None)\n",
    "df.columns = feature_names + [label]\n",
    "\n",
    "df.replace(to_replace='?',value = np.nan, inplace=True) # replace '?' with nans\n",
    "\n",
    "df = df.astype(float) # column types need to be numeric for the mcar_test to work\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 (4 points):\n",
    "\n",
    "Please handle the missing values in the data and justify your decision. If you decide to drop the points with missing values, please use `.reset_index(drop=True, inplace=True)` on your dataframe after droping the rows to avoid any issues with the index column down the road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0.000000\n",
      "sex         0.000000\n",
      "cp          0.000000\n",
      "trestbps    0.000000\n",
      "chol        0.000000\n",
      "fbs         0.000000\n",
      "restecg     0.000000\n",
      "thalach     0.000000\n",
      "exang       0.000000\n",
      "oldpeak     0.000000\n",
      "slope       0.000000\n",
      "ca          0.013201\n",
      "thal        0.006601\n",
      "num         0.000000\n",
      "dtype: float64\n",
      "0.019801980198019802\n"
     ]
    }
   ],
   "source": [
    "# print(df.shape)\n",
    "print(df.isnull().sum(axis=0)/df.shape[0])\n",
    "print(sum(df.isnull().sum(axis=1)!=0)/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**   \n",
    "As we can see in the description of the data file, both 'ca' and 'thal' are categorical features. Since they are the only two feature contains missing values, we can treat the missing values as one separate category of each. Since the catagories are represented by integers and none of the categories is 9, we define the missing catagory as 9. For preprocessing the missing values, we deal it with the one-hot encoder, so the missing value will be handled in problem 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: (8 points)\n",
    "\n",
    "Please preprocess the features. If you can't complete this within 30 min, move on to problems 3 and 4. If preprocessing is not completed, you can still get full points for problems 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sex, exang, and fbs are already binary features, which means we don't need to preprocess them. \n",
    "bin_ftrs = ['sex','exang','fbs']\n",
    "cat_ftrs = ['cp','restecg','slope', 'ca', 'thal']\n",
    "num_ftrs = ['age', 'trestbps','chol','thalach','oldpeak']\n",
    "label = ['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_0.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_9.0</th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex</th>\n",
       "      <th>exang</th>\n",
       "      <th>fbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948726</td>\n",
       "      <td>0.757525</td>\n",
       "      <td>-0.264900</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>1.087338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392002</td>\n",
       "      <td>1.611220</td>\n",
       "      <td>0.760415</td>\n",
       "      <td>-1.821905</td>\n",
       "      <td>0.397182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392002</td>\n",
       "      <td>-0.665300</td>\n",
       "      <td>-0.342283</td>\n",
       "      <td>-0.902354</td>\n",
       "      <td>1.346147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.932564</td>\n",
       "      <td>-0.096170</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>1.637359</td>\n",
       "      <td>2.122573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.489288</td>\n",
       "      <td>-0.096170</td>\n",
       "      <td>-0.825922</td>\n",
       "      <td>0.980537</td>\n",
       "      <td>0.310912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
       "0     1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
       "1     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
       "2     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
       "3     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
       "4     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
       "\n",
       "   slope_1.0  slope_2.0  slope_3.0  ...  thal_7.0  thal_9.0       age  \\\n",
       "0        0.0        0.0        1.0  ...       0.0       0.0  0.948726   \n",
       "1        0.0        1.0        0.0  ...       0.0       0.0  1.392002   \n",
       "2        0.0        1.0        0.0  ...       1.0       0.0  1.392002   \n",
       "3        0.0        0.0        1.0  ...       0.0       0.0 -1.932564   \n",
       "4        1.0        0.0        0.0  ...       0.0       0.0 -1.489288   \n",
       "\n",
       "   trestbps      chol   thalach   oldpeak  sex  exang  fbs  \n",
       "0  0.757525 -0.264900  0.017197  1.087338  1.0    0.0  1.0  \n",
       "1  1.611220  0.760415 -1.821905  0.397182  1.0    1.0  0.0  \n",
       "2 -0.665300 -0.342283 -0.902354  1.346147  1.0    1.0  0.0  \n",
       "3 -0.096170  0.063974  1.637359  2.122573  1.0    0.0  0.0  \n",
       "4 -0.096170 -0.825922  0.980537  0.310912  0.0    0.0  0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "si = SimpleImputer(strategy='constant',fill_value=9)\n",
    "cat_values = ohe.fit_transform(si.fit_transform(df[cat_ftrs]))\n",
    "cat_ftr_names = ohe.get_feature_names(cat_ftrs)\n",
    "df_cat = pd.DataFrame(data=cat_values,columns = cat_ftr_names)\n",
    "df_bin = df[bin_ftrs]\n",
    "\n",
    "# standard scaler\n",
    "ss = StandardScaler()\n",
    "num_values = ss.fit_transform(df[num_ftrs])\n",
    "df_num = pd.DataFrame(data=num_values,columns = num_ftrs)\n",
    "\n",
    "label\n",
    "le = LabelEncoder()\n",
    "label_values = le.fit_transform(df[label])\n",
    "df_label = pd.DataFrame(data=label_values, columns = label)\n",
    "\n",
    "df_preprocessed = pd.concat([df_cat,df_num,df_bin],axis=1)\n",
    "print(df_preprocessed.shape)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3: (5 points)\n",
    "\n",
    "Which feature has the strongest linear dependency with the target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['thal_3.0'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: need to use select k best, instead of correlation\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "X = df_preprocessed.values\n",
    "# change matrix to array\n",
    "y = df_label.values.ravel()\n",
    "# need to have this line in order to run the code\n",
    "feature_names = df_preprocessed.columns\n",
    "f_select = SelectKBest(f_regression,k=1)\n",
    "X_f = f_select.fit_transform(X,y)\n",
    "f_select.get_support()\n",
    "feature_names[f_select.get_support()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**    \n",
    "I get the correlation matrix from the pre processed data, and the feature 'thal_3.0' is has the strongest linear dependency with 'num'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4: (3 points)\n",
    "\n",
    "Prepare one visualization using the feature selected above and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (14,9))\n",
    "f = sns.boxplot(x='num', y='oldpeak', data=df)\n",
    "f.set_xticklabels(f.get_xticklabels(),rotation=90, fontsize = 16)\n",
    "f.set_title(\"oldpeak by num\", fontsize=20)\n",
    "f.set_xlabel(\"num\", fontsize=15)\n",
    "f.set_ylabel(\"oldpeak\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_preprocessed = pd.concat([df_preprocessed,df_label],axis=1)\n",
    "df_preprocessed\n",
    "corrmat = df_preprocessed.corr()\n",
    "\n",
    "all_cols = corrmat.sort_values('num',ascending=False)['num'].index \n",
    "cols = all_cols[:10] # positively correlated features\n",
    "\n",
    "cm = corrmat.loc[cols,cols]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.matshow(cm,vmin=-1,vmax=1,cmap='seismic',fignum=0)\n",
    "plt.colorbar(label='corr. coeff.')\n",
    "plt.xticks(np.arange(cm.shape[0]),list(cols),rotation=90)\n",
    "plt.yticks(np.arange(cm.shape[0]),list(cols))\n",
    "plt.tight_layout()\n",
    "plt.title(\"correlation matrix\", fontsize = 15)\n",
    "# plt.savefig('figures/corr_coeff_dummies.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1) We will create a kfold CV pipeline for the heart disease dataset you worked with during the midterm exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1a) Read in the data and drop the rows with missing values. Remember that the dataset does not contain the feature names! Separate out the feature matrix (X) and the target variable (y). What is the balance of this dataset (the baseline accuracy)? (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balance of the dataset is 53.87 %\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('data/cleveland.data',header=None)\n",
    "\n",
    "# set feature and label names\n",
    "feature_names = ['age','sex','cp','trestbps','chol','fbs','restecg',\n",
    "                 'thalach','exang','oldpeak','slope','ca','thal']\n",
    "label = 'num'\n",
    "df.columns = feature_names + [label]\n",
    "\n",
    "# replace '?' with nans\n",
    "df.replace(to_replace='?',value = np.nan, inplace=True)\n",
    "\n",
    "# drop the rows with missing value\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Separate out the feature matrix (X) and the target variable (y)\n",
    "X = df[feature_names]\n",
    "y = df[label]\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "# What is the balance of this dataset (the baseline accuracy)?\n",
    "balance = df[label].value_counts()/df[label].shape\n",
    "print(\"The balance of the dataset is\", np.around(balance[0],4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1b) ML pipeline with logistic regression\n",
    "\n",
    "Split your data in a stratified manner into `other` and `test` (20% in `test`) and then split `other` into 5 stratified folds. 4 of those folds will be used for training, the last fold will be CV. You'll need to loop through the 5 options the CV fold can be selected. (4 points)\n",
    "\n",
    "Preprocess the data. Apply the OneHotEncoder and the StandardScaler to the appropriate columns. Make sure to fit_transform only train (4 out of the 5 folds). The CV and test sets should be transformed based on the preprocessor fitted to train. (2 points)\n",
    "\n",
    "Train a logistic regression model with l1 regularization and tune the appropriate parameter. (4 points)\n",
    "\n",
    "Repeat the procedure 10 times with 10 different random states and print the mean and std of the test accuracy score. Make sure to print the best parameters and check that the best values are not at the edge of your parameter space if possible. Check that your code is reproducable! That is, if you rerun the cell, you get back the exact same result. (3 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is 0.01\n",
      "The best alpha is 0.517947467923121\n",
      "The best alpha is 1.9306977288832496\n",
      "The best alpha is 0.01\n",
      "The best alpha is 0.01\n",
      "The best alpha is 1.9306977288832496\n",
      "The best alpha is 0.517947467923121\n",
      "The best alpha is 0.517947467923121\n",
      "The best alpha is 7.196856730011514\n",
      "The best alpha is 1.9306977288832496\n",
      "Lasso best accuracy is  0.58 +/- 0.03\n"
     ]
    }
   ],
   "source": [
    "# train lasso\n",
    "def ML_pipeline_kfold(X,y,random_state,n_folds):\n",
    "    # split the data\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state = random_state, stratify = y)\n",
    "    CV_scores = []\n",
    "    test_scores = []\n",
    "    # k folds - each fold will give us a CV and a test score\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # loop through 5 selected folders\n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other[train_index], X_other[CV_index]\n",
    "        y_train, y_CV = y_other[train_index], y_other[CV_index]\n",
    "    \n",
    "        label = ['num']\n",
    "        # preprocessing - continuous feature\n",
    "        scaler = StandardScaler()\n",
    "#         num_ftrs = ['age', 'trestbps','chol','thalach','oldpeak']\n",
    "        num_ftrs = [0,3,4,7,9]\n",
    "        X_train_num = scaler.fit_transform(X_train[:,num_ftrs])\n",
    "        X_c_num = scaler.transform(X_CV[:,num_ftrs])\n",
    "        X_t_num = scaler.transform(X_test[:,num_ftrs])\n",
    "\n",
    "        # preprocessing - cat features\n",
    "        ohe = OneHotEncoder(sparse = False, handle_unknown = \"ignore\")\n",
    "#         cat_ftrs = ['sex', 'cp', 'fbs', 'restecg','exang','slope', 'ca', 'thal']\n",
    "#         cat_ftrs = [1,2,5,6,8,10,11,12]\n",
    "        cat_ftrs = [2,10,12]\n",
    "        X_train_cat = ohe.fit_transform(X_train[:,cat_ftrs])\n",
    "#         print('X_train_cat', X_train_cat)\n",
    "        X_c_cat = ohe.transform(X_CV[:,cat_ftrs])\n",
    "#         print('X_c_cat', X_c_cat)\n",
    "        X_t_cat = ohe.transform(X_test[:,cat_ftrs])\n",
    "        \n",
    "        # binary features\n",
    "#         bin_ord_ftrs = ['sex', 'fbs', 'exang', 'ca', 'restecg']\n",
    "        bi_ftrs = [1,5,6,8,11]\n",
    "        X_train_bi = X_train[:,bi_ftrs]\n",
    "        X_c_bi = X_CV[:,bi_ftrs]\n",
    "        X_t_bi = X_test[:,bi_ftrs]\n",
    "\n",
    "        X_train_prep = np.concatenate((X_train_cat,X_train_num,X_train_bi),axis=1)\n",
    "        X_c = np.concatenate((X_c_cat,X_c_num, X_c_bi),axis=1)\n",
    "        X_t = np.concatenate((X_t_cat,X_t_num, X_t_bi),axis=1)\n",
    "        X_train = X_train_prep\n",
    "        \n",
    "        # tune lasso hyper-parameter, alpha\n",
    "        alpha = np.logspace(-2,2,num=8)\n",
    "        train_score = []\n",
    "        CV_score = []\n",
    "        regs = []\n",
    "        for a in alpha:\n",
    "            reg = LogisticRegression(penalty='l1',C = 1/a, multi_class = 'multinomial', \n",
    "                                     solver='saga', max_iter = 1e4)\n",
    "            reg.fit(X_train,y_train)\n",
    "            train_score.append(accuracy_score(y_train,reg.predict(X_train)))\n",
    "            CV_score.append(accuracy_score(y_CV,reg.predict(X_c)))\n",
    "            regs.append(reg)\n",
    "        # find the best alpha in this fold\n",
    "        best_alpha = alpha[np.argmax(CV_score)]\n",
    "        # grab the best model\n",
    "        reg = regs[np.argmax(CV_score)]\n",
    "        CV_scores.append(np.max(CV_score))\n",
    "        # calculate test score using the best model\n",
    "        test_scores.append(accuracy_score(y_test,reg.predict(X_t)))\n",
    "        \n",
    "    print(\"The best alpha is\", best_alpha)\n",
    "    return CV_scores,test_scores\n",
    "\n",
    "test_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    grid, test_score = ML_pipeline_kfold(X,y,42*i,5)\n",
    "    test_scores.append(test_score)\n",
    "print(\"Lasso best accuracy is \",np.around(np.mean(test_scores),2), '+/-', np.around(np.std(test_scores),2))\n",
    "\n",
    "# Lasso best accuracy is  0.58 +/- 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1d) Train a random forest classifier and tune the appropriate parameters. Make sure to print the best parameters and check that the best values are not at the edge of your parameter space if possible. Repeat the procedure 10 times with 10 different random states and print the mean and std of the test accuracy score. Check that your code is reproducable! That is, if you rerun the cell, you get back the exact same result. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best max_depths is  3\n",
      "best min sample splits is  12\n",
      "best max_depths is  7\n",
      "best min sample splits is  5\n",
      "best max_depths is  4\n",
      "best min sample splits is  9\n",
      "best max_depths is  4\n",
      "best min sample splits is  5\n",
      "best max_depths is  7\n",
      "best min sample splits is  8\n",
      "best max_depths is  7\n",
      "best min sample splits is  11\n",
      "best max_depths is  2\n",
      "best min sample splits is  5\n",
      "best max_depths is  6\n",
      "best min sample splits is  11\n",
      "best max_depths is  9\n",
      "best min sample splits is  8\n",
      "best max_depths is  4\n",
      "best min sample splits is  14\n",
      "Random Tree best accuracy is  0.58 +/- 0.03\n"
     ]
    }
   ],
   "source": [
    "# train random forest\n",
    "def ML_pipeline_kfold(X,y,random_state,n_folds):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state, stratify = y)\n",
    "    CV_scores = []\n",
    "    test_scores = []\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True,random_state=random_state)\n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other[train_index], X_other[CV_index]\n",
    "        y_train, y_CV = y_other[train_index], y_other[CV_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "#         num_ftrs = ['age', 'trestbps','chol','thalach','oldpeak']\n",
    "        num_ftrs = [0,3,4,7,9]\n",
    "        X_train_num = scaler.fit_transform(X_train[:,num_ftrs])\n",
    "        X_c_num = scaler.transform(X_CV[:,num_ftrs])\n",
    "        X_t_num = scaler.transform(X_test[:,num_ftrs])\n",
    "\n",
    "        # preprocessing - cat features\n",
    "        ohe = OneHotEncoder(sparse = False, handle_unknown = \"ignore\")\n",
    "#         cat_ftrs = ['sex', 'cp', 'fbs', 'restecg','exang','slope', 'ca', 'thal']\n",
    "#         cat_ftrs = [1,2,5,6,8,10,11,12]\n",
    "        cat_ftrs = [2,10,12]\n",
    "        X_train_cat = ohe.fit_transform(X_train[:,cat_ftrs])\n",
    "#         print('X_train_cat', X_train_cat)\n",
    "        X_c_cat = ohe.transform(X_CV[:,cat_ftrs])\n",
    "#         print('X_c_cat', X_c_cat)\n",
    "        X_t_cat = ohe.transform(X_test[:,cat_ftrs])\n",
    "        \n",
    "        # binary features\n",
    "#         bin_ord_ftrs = ['sex', 'fbs', 'exang', 'ca', 'restecg']\n",
    "        bi_ftrs = [1,5,6,8,11]\n",
    "        X_train_bi = X_train[:,bi_ftrs]\n",
    "        X_c_bi = X_CV[:,bi_ftrs]\n",
    "        X_t_bi = X_test[:,bi_ftrs]\n",
    "\n",
    "        X_train_prep = np.concatenate((X_train_cat,X_train_num,X_train_bi),axis=1)\n",
    "        X_c = np.concatenate((X_c_cat,X_c_num, X_c_bi),axis=1)\n",
    "        X_t = np.concatenate((X_t_cat,X_t_num, X_t_bi),axis=1)\n",
    "        X_train = X_train_prep\n",
    "\n",
    "        # tune random forest hyper-parameter, depth and min sample split\n",
    "        depths = [i for i in range(1,15)]\n",
    "        sss = [i for i in range(5,15)]\n",
    "        train_score = defaultdict(lambda: 0)\n",
    "        CV_score = defaultdict(lambda: 0)\n",
    "        regs = defaultdict(lambda: RandomForestClassifier(n_estimators=10, max_depth=2, min_samples_split=2, random_state=random_state))\n",
    "        for i,depth in enumerate(depths):\n",
    "            for j,ss in enumerate(sss):\n",
    "                reg = RandomForestClassifier(n_estimators=10, max_depth=depth, min_samples_split=ss, random_state=random_state)\n",
    "                reg.fit(X_train, y_train)\n",
    "                train_score[(i,j)] = accuracy_score(y_train, reg.predict(X_train))\n",
    "                CV_score[(i,j)] = accuracy_score(y_CV, reg.predict(X_c))\n",
    "                regs[(i,j)] = reg\n",
    "        # find the best alpha in this fold\n",
    "        best_CV_pair = max(CV_score, key=CV_score.get)\n",
    "        best_depths = depths[best_CV_pair[0]]\n",
    "        best_sss = sss[best_CV_pair[1]]\n",
    "        # grab the best model\n",
    "        reg = regs[best_CV_pair]\n",
    "        CV_scores.append(np.max(CV_score))\n",
    "        # calculate test score using thee best model\n",
    "        test_scores.append(accuracy_score(y_test, reg.predict(X_t)))\n",
    "    \n",
    "    print(\"best max_depths is \", best_depths)\n",
    "    print(\"best min sample splits is \", best_sss)\n",
    "    return CV_scores, test_scores\n",
    "\n",
    "\n",
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score = ML_pipeline_kfold(X,y,42*i,5)\n",
    "    test_scores.append(test_score)\n",
    "print(\"Random Tree best accuracy is \",np.around(np.mean(test_scores),2), '+/-', np.around(np.std(test_scores),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1e) Train an SVC and tune the appropriate parameters. Make sure to print the best parameters and check that the best values are not at the edge of your parameter space if possible. Repeat the procedure 10 times with 10 different random states and print the mean and std of the test accuracy score. Check that your code is reproducable! That is, if you rerun the cell, you get back the exact same result. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best gamma is  1e-07\n",
      "best c is  100000.0\n",
      "best gamma is  0.01\n",
      "best c is  100.0\n",
      "best gamma is  1e-09\n",
      "best c is  100000000.0\n",
      "best gamma is  0.001\n",
      "best c is  1000.0\n",
      "best gamma is  0.001\n",
      "best c is  10000.0\n",
      "best gamma is  1e-06\n",
      "best c is  100000.0\n",
      "best gamma is  1.0\n",
      "best c is  10.0\n",
      "best gamma is  1e-08\n",
      "best c is  100000000.0\n",
      "best gamma is  1e-06\n",
      "best c is  10000000.0\n",
      "best gamma is  1e-08\n",
      "best c is  10000000.0\n",
      "SVC best accuracy is  0.56 +/- 0.04\n"
     ]
    }
   ],
   "source": [
    "# Train an SVC\n",
    "\n",
    "def ML_pipeline_kfold(X,y,random_state,n_folds):\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state, stratify = y)\n",
    "    CV_scores = []\n",
    "    test_scores = []\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True,random_state=random_state)\n",
    "    for train_index, CV_index in kf.split(X_other,y_other):\n",
    "        X_train, X_CV = X_other[train_index], X_other[CV_index]\n",
    "        y_train, y_CV = y_other[train_index], y_other[CV_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "#         num_ftrs = ['age', 'trestbps','chol','thalach','oldpeak']\n",
    "        num_ftrs = [0,3,4,7,9]\n",
    "        X_train_num = scaler.fit_transform(X_train[:,num_ftrs])\n",
    "        X_c_num = scaler.transform(X_CV[:,num_ftrs])\n",
    "        X_t_num = scaler.transform(X_test[:,num_ftrs])\n",
    "\n",
    "        # preprocessing - cat features\n",
    "        ohe = OneHotEncoder(sparse = False, handle_unknown = \"ignore\")\n",
    "#         cat_ftrs = ['sex', 'cp', 'fbs', 'restecg','exang','slope', 'ca', 'thal']\n",
    "#         cat_ftrs = [1,2,5,6,8,10,11,12]\n",
    "        cat_ftrs = [2,10,12]\n",
    "        X_train_cat = ohe.fit_transform(X_train[:,cat_ftrs])\n",
    "#         print('X_train_cat', X_train_cat)\n",
    "        X_c_cat = ohe.transform(X_CV[:,cat_ftrs])\n",
    "#         print('X_c_cat', X_c_cat)\n",
    "        X_t_cat = ohe.transform(X_test[:,cat_ftrs])\n",
    "        \n",
    "        # binary features\n",
    "#         bin_ord_ftrs = ['sex', 'fbs', 'exang', 'ca', 'restecg']\n",
    "        bi_ftrs = [1,5,6,8,11]\n",
    "        X_train_bi = X_train[:,bi_ftrs]\n",
    "        X_c_bi = X_CV[:,bi_ftrs]\n",
    "        X_t_bi = X_test[:,bi_ftrs]\n",
    "\n",
    "        X_train_prep = np.concatenate((X_train_cat,X_train_num,X_train_bi),axis=1)\n",
    "        X_c = np.concatenate((X_c_cat,X_c_num, X_c_bi),axis=1)\n",
    "        X_t = np.concatenate((X_t_cat,X_t_num, X_t_bi),axis=1)\n",
    "        X_train = X_train_prep\n",
    "\n",
    "        # tune svc hyper-parameter, gamma and c \n",
    "        gammas= np.logspace(-9, 3, 13)\n",
    "        Cs = np.logspace(1, 10, 10)\n",
    "        train_score = defaultdict(lambda: 0)\n",
    "        CV_score = defaultdict(lambda: 0)\n",
    "        regs = defaultdict(lambda: SVC(gamma = 1, C = 1, probability=True, random_state=random_state))\n",
    "        for i,gamma_value in enumerate(gammas):\n",
    "            for j,c in enumerate(Cs):\n",
    "                reg = SVC(gamma = gamma_value, C = c, probability=True)\n",
    "                reg.fit(X_train, y_train)\n",
    "                train_score[(i,j)] = accuracy_score(y_train, reg.predict(X_train))\n",
    "                CV_score[(i,j)] = accuracy_score(y_CV, reg.predict(X_c))\n",
    "                regs[(i,j)] = reg\n",
    "        # find the best alpha in this fold\n",
    "        best_CV_pair = max(CV_score, key=CV_score.get)\n",
    "        best_gamma = gammas[best_CV_pair[0]]\n",
    "        best_c = Cs[best_CV_pair[1]]\n",
    "        # grab the best model\n",
    "        reg = regs[best_CV_pair]\n",
    "        CV_scores.append(np.max(CV_score))\n",
    "        # calculate test score using thee best model\n",
    "        test_scores.append(accuracy_score(y_test, reg.predict(X_t)))\n",
    "    \n",
    "    print(\"best gamma is \", best_gamma)\n",
    "    print(\"best c is \", best_c)\n",
    "    return CV_scores, test_scores\n",
    "\n",
    "test_scores = []\n",
    "for i in range(10):\n",
    "    grid, test_score = ML_pipeline_kfold(X,y,42*i,5)\n",
    "    test_scores.append(test_score)\n",
    "print(\"SVC best accuracy is \",np.around(np.mean(test_scores),2), '+/-', np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1f) Compare the means and standard deviations of the three techniques. How many standard deviations above the baseline accuracy are the three models? How would you rank them with respect of accuracy? (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regularization: 1.376666666666667\n",
      "Random Forest: 1.376666666666667\n",
      "SVC: 0.5325000000000024\n"
     ]
    }
   ],
   "source": [
    "# 1f)\n",
    "print(\"Lasso regularization:\", (0.58-0.5387)/0.03)\n",
    "print(\"Random Forest:\", (0.58-0.5387)/0.03)\n",
    "print(\"SVC:\", (0.56-0.5387)/0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**   \n",
    "The random forest and the Lasso regularization are better than the SVC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
